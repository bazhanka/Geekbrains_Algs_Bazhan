{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41AitfhKbsha"
      },
      "source": [
        "# Урок 6. Градиентный бустинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg5ilDbTbshs"
      },
      "source": [
        "### Стохастический градиентный бустинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJrobWhDbsht"
      },
      "source": [
        "Как и в случае с градиентым спуском, есть так называемый стохастический градиентный бустинг, являющийся упрощенной (в плане потребления ресурсов) версией алгоритма. Его суть заключается в обучении каждого нового базового алгоритма на новой итерации не на всей обучающей выборке, а на некоторой ее случайной подвыборке. Практика показывает, что такой алгоритм позволяет получить такую же ошибку или даже уменьшить ее при том же числе итераций, что и в случае использования обычного бустинга."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qk-74OFhbshx"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "from sklearn import model_selection\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eDZbSvqMbsh1"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leu8bBI7bsh6",
        "outputId": "fbac3723-2a0d-4101-837c-0f39140ceb80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((442, 10), (442,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X, y = load_diabetes(return_X_y=True)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz_JhiIpbsh8"
      },
      "source": [
        "Разделим выборку на обучающую и тестовую в соотношении 75/25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ExZPR9FLbsh9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wU_Rkc63bsiA"
      },
      "outputs": [],
      "source": [
        "def gb_predict(X, trees_list, coef_list, eta):\n",
        "    # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
        "    # поэтому все деревья из списка trees_list уже являются дополнительными и при предсказании \n",
        "    # прибавляются с шагом eta\n",
        "    return np.array([sum([\n",
        "        eta * coef * alg.predict([x])[0] for alg, coef in zip(trees_list, coef_list)]) \n",
        "                     for x in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gZvsyfSbsiD"
      },
      "source": [
        "В качестве функционала ошибки будем использовать среднеквадратичную ошибку. Реализуем соответствующую функцию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0xbjFIEKbsiE"
      },
      "outputs": [],
      "source": [
        "def mean_squared_error(y_real, prediction):\n",
        "    return (sum((y_real - prediction) ** 2)) / len(y_real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlr3KD6zbsiH"
      },
      "source": [
        "Используем $L_{2}$ loss $L(y, z) = (y-z)^{2},$ ее производная по $z$ примет вид $L'(y, z) = 2(z-y)$. Тогда сдвиг будет равен $s =- L'(y, z)$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WRaZEd3ebsiI"
      },
      "outputs": [],
      "source": [
        "def bias(y, z):\n",
        "    return - 2 * (z - y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut-7dBgVbsiK"
      },
      "source": [
        "Реализуем функцию обучения градиентного бустинга."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HoIdAoPYbsiL"
      },
      "outputs": [],
      "source": [
        "def gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
        "    \n",
        "    # eta - скорость обучения\n",
        "    # Деревья будем записывать в список\n",
        "    trees = []\n",
        "    \n",
        "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "    \n",
        "    for i in range(n_trees):\n",
        "        tree = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
        "\n",
        "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
        "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
        "        if len(trees) == 0:\n",
        "            # обучаем первое дерево на обучающей выборке\n",
        "            tree.fit(X_train, y_train)\n",
        "            \n",
        "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
        "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
        "        else:\n",
        "            # Получим ответы на текущей композиции\n",
        "            z_train = gb_predict(X_train, trees, coefs, eta)\n",
        "            \n",
        "            # алгоритмы, начиная со второго, обучаем на сдвиг\n",
        "            tree.fit(X_train, bias(y_train, z_train))\n",
        "            \n",
        "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
        "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
        "\n",
        "        trees.append(tree)\n",
        "        \n",
        "    return trees, train_errors, test_errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vkHFhhzbsiN"
      },
      "source": [
        "Теперь обучим несколько моделей с разными параметрами и исследуем их поведение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GDMFn3R-bsiR"
      },
      "outputs": [],
      "source": [
        "def evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta):\n",
        "    \n",
        "    train_prediction = gb_predict(X_train, trees, coefs, eta)\n",
        "\n",
        "    mse_train = mean_squared_error(y_train, train_prediction)\n",
        "\n",
        "    test_prediction = gb_predict(X_test, trees, coefs, eta)\n",
        "\n",
        "    mse_test = mean_squared_error(y_test, test_prediction)\n",
        "\n",
        "    return mse_train, mse_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Число деревьев в ансамбле\n",
        "n_trees = 25\n",
        "\n",
        "# для простоты примем коэффициенты равными 1\n",
        "coefs = [1] * n_trees\n",
        "\n",
        "# Максимальная глубина деревьев\n",
        "max_depth = 3\n",
        "\n",
        "# Шаг\n",
        "eta = 0.05\n",
        "\n",
        "all_eta = []\n",
        "all_mse_train = []\n",
        "all_mse_test = []\n",
        "\n",
        "while eta <= 0.5:\n",
        "    all_eta.append(eta)\n",
        "    trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)\n",
        "    mse_train, mse_test = evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)\n",
        "    all_mse_train.append(mse_train)\n",
        "    all_mse_test.append(mse_test)\n",
        "    eta += 0.05\n",
        "\n",
        "print(all_mse_train, all_mse_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzFFNY-0yGu5",
        "outputId": "3124dcc2-68fd-48bd-a9b8-3ac96375422d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2103.825428374197, 1356.3728316052907, 1160.3183304666686, 822.9548349927874, 724.6999711112796, 620.069530264813, 480.54637719869476, 478.69361633675504, 398.65020637573787, 412.71574181107525] [2993.4572220304362, 3210.037824305435, 3293.2184446790975, 3453.413378143705, 3796.3893338873004, 3478.3872645200763, 4202.457944591111, 4032.445709300567, 5577.896684393286, 5302.251461590757]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TluGn7Iubsib"
      },
      "source": [
        "Построим графики зависимости ошибки на обучающей и тестовой выборках от числа итераций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QXrSdSgjbsic"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gjDdKkgObsif"
      },
      "outputs": [],
      "source": [
        "def get_error_plot(all_eta, all_mse_train, all_mse_test):\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.xlim(0.1, 0.5)\n",
        "    plt.plot(all_eta, all_mse_train, label='train error')\n",
        "    plt.plot(all_eta, all_mse_test, label='test error')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Was5hOJPbsih",
        "outputId": "187c7409-7005-4247-fb0b-02ccdf5314d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "get_error_plot(all_eta, all_mse_train, all_mse_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Число деревьев в ансамбле\n",
        "n_trees = 25\n",
        "\n",
        "# для простоты примем коэффициенты равными 1\n",
        "coefs = [1] * n_trees\n",
        "\n",
        "# Максимальная глубина деревьев\n",
        "max_depth = 1\n",
        "\n",
        "# Шаг\n",
        "eta = 0.5\n",
        "\n",
        "all_depth = []\n",
        "all_mse_train = []\n",
        "all_mse_test = []\n",
        "\n",
        "while max_depth <= 20:\n",
        "    all_depth.append(max_depth)\n",
        "    trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)\n",
        "    mse_train, mse_test = evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)\n",
        "    all_mse_train.append(mse_train)\n",
        "    all_mse_test.append(mse_test)\n",
        "    max_depth += 1\n",
        "\n",
        "print(all_mse_train, all_mse_test)"
      ],
      "metadata": {
        "id": "DNECS63H0qNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Max depth')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlim(1, 20)\n",
        "plt.plot(all_depth, all_mse_train, label='train error')\n",
        "plt.plot(all_depth, all_mse_test, label='test error')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KN1iTErl1M8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABXyo_mVrdku"
      },
      "source": [
        "## Домашние задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb641sUQrdku"
      },
      "source": [
        "1. Задание.\n",
        "    - Для реализованной в методичке модели градиентного бустинга построить графики зависимости ошибки от количества деревьев при разных значениях шага градиента и для разной глубины деревьев. \n",
        "    - Сделать выводы о зависимости ошибки от этих гиперпараметров (шаг градиента, максимальная глубина деревьев, количество деревьев). \n",
        "    - Подобрать оптимальные значения этих гиперпараметров (минимум ошибки на тесте при отсутствии переобучения).\n",
        "\n",
        "2. (\\*) Модифицировать реализованный алгоритм, чтобы получился стохастический градиентный бустинг. Размер подвыборки принять равным 0.5.    Сравнить на одном графике кривые  изменения ошибки на тестовой выборке в зависимости от  числа итераций.\n",
        "\n",
        "3. (\\*) Модифицировать алгоритм градиентного бустинга, взяв за основу реализацию решающего дерева из ДЗ_4 (для задачи регрессии). Сделать выводы о качестве алгоритма по сравнению с реализацией из п.1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    \n",
        "    def __init__(self, index, t, true_branch, false_branch):\n",
        "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
        "        self.t = t  # значение порога\n",
        "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
        "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
      ],
      "metadata": {
        "id": "_w1DBwxp8lXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gb_predict(X, trees_list, coef_list, eta):\n",
        "    # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
        "    # поэтому все деревья из списка trees_list уже являются дополнительными и при предсказании \n",
        "    # прибавляются с шагом eta\n",
        "    return np.array([sum([\n",
        "        eta * coef * predict(X, alg)[0] for alg, coef in zip(trees_list, coef_list)]) \n",
        "                     for x in X])"
      ],
      "metadata": {
        "id": "KOGQxKa7ACOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKscbwFtrdkv"
      },
      "outputs": [],
      "source": [
        "class Reg_Leaf:\n",
        "    \n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.prediction = self.predict()\n",
        "        \n",
        "    def predict(self):\n",
        "        prediction = np.mean(self.labels)\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиение датасета в узле\n",
        "\n",
        "def split(data, labels, index, t):\n",
        "    \n",
        "    left = np.where(data[:, index] <= t)\n",
        "    right = np.where(data[:, index] > t)\n",
        "        \n",
        "    true_data = data[left]\n",
        "    false_data = data[right]\n",
        "    true_labels = labels[left]\n",
        "    false_labels = labels[right]\n",
        "        \n",
        "    return true_data, false_data, true_labels, false_labels"
      ],
      "metadata": {
        "id": "0aFXOzsp8qsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reg_quality(left_labels, right_labels, current_criterion):\n",
        "\n",
        "    # доля выбоки, ушедшая в левое поддерево\n",
        "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
        "\n",
        "    return current_criterion - p * np.var(left_labels) - (1 - p) * np.var(right_labels)"
      ],
      "metadata": {
        "id": "ZX6PHc_C81Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reg_find_best_split(data, labels, min_leaf):\n",
        "\n",
        "    current_criterion = np.var(data)\n",
        "      \n",
        "    best_quality = 0\n",
        "    best_t = None\n",
        "    best_index = None\n",
        "    \n",
        "    n_features = data.shape[1]\n",
        "    \n",
        "    for index in range(n_features):\n",
        "        # будем проверять только уникальные значения признака, исключая повторения\n",
        "        t_values = np.unique([row[index] for row in data])\n",
        "        \n",
        "        for t in t_values:\n",
        "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
        "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
        "                continue\n",
        "        \n",
        "            current_quality = reg_quality(true_data, false_data, current_criterion)\n",
        "            \n",
        "            #  выбираем порог, на котором получается максимальный прирост качества\n",
        "            if current_quality > best_quality:\n",
        "                best_quality, best_t, best_index = current_quality, t, index\n",
        "\n",
        "    return best_quality, best_t, best_index"
      ],
      "metadata": {
        "id": "teKxot7s86im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reg_build_tree(data, labels, min_leaf=5, max_depth=None, depth=0, max_leaves=1000):\n",
        "    \n",
        "    quality, t, index = reg_find_best_split(data, labels, min_leaf)\n",
        "\n",
        "    global counter_node\n",
        "    global counter_leaf\n",
        "\n",
        "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
        "    if quality == 0:\n",
        "        counter_leaf += 1\n",
        "        return Reg_Leaf(data, labels)\n",
        "\n",
        "    if (max_depth is not None) and (depth >= max_depth):\n",
        "        counter_leaf += 1\n",
        "        return Reg_Leaf(data, labels)\n",
        "\n",
        "    if max_leaves is not None:\n",
        "        if counter_leaf <= max_leaves or counter_node <= (max_leaves/2):\n",
        "              true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "              counter_node += 1\n",
        "              depth += 1\n",
        "\n",
        "    # Рекурсивно строим два поддерева\n",
        "              true_branch = reg_build_tree(true_data, true_labels, \n",
        "                                     min_leaf, max_depth, depth, (max_leaves-counter_leaf))\n",
        "              false_branch = reg_build_tree(false_data, false_labels, \n",
        "                                      min_leaf, max_depth, depth, (max_leaves-counter_leaf))\n",
        "        elif (counter_leaf > max_leaves) or ((counter_node + 1) > (max_leaves / 2)):\n",
        "              counter_leaf += 1\n",
        "              return Reg_Leaf(data, labels)\n",
        "        \n",
        "    else:\n",
        "        true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "        counter_node += 1\n",
        "        depth += 1 \n",
        "\n",
        "        # Рекурсивно строим два поддерева\n",
        "        true_branch = reg_build_tree(true_data, true_labels, \n",
        "                                 min_leaf, max_depth, depth, max_leaves)\n",
        "        false_branch = reg_build_tree(false_data, false_labels, \n",
        "                                  min_leaf, max_depth, depth, max_leaves)\n",
        "    \n",
        "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
        "    return Node(index, t, true_branch, false_branch)"
      ],
      "metadata": {
        "id": "JMmB_wBb8-q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse (y, y_pred):\n",
        "  return np.mean ((y - y_pred)**2)"
      ],
      "metadata": {
        "id": "9TA6UY_j9C9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_object(obj, node):\n",
        "\n",
        "    #  Останавливаем рекурсию, если достигли листа\n",
        "    if isinstance(node, Reg_Leaf):\n",
        "        answer = node.prediction\n",
        "        return answer\n",
        "\n",
        "    if obj[node.index] <= node.t:\n",
        "        return classify_object(obj, node.true_branch)\n",
        "    else:\n",
        "        return classify_object(obj, node.false_branch)"
      ],
      "metadata": {
        "id": "9pyBp5IgBgyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(data, tree):\n",
        "    \n",
        "    classes = []\n",
        "    for obj in data:\n",
        "        prediction = classify_object(obj, tree)\n",
        "        classes.append(prediction)\n",
        "    return classes"
      ],
      "metadata": {
        "id": "m3rJm9tVBhXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reg_gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
        "    \n",
        "    # eta - скорость обучения\n",
        "    # Деревья будем записывать в список\n",
        "    trees = []\n",
        "    \n",
        "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "    \n",
        "\n",
        "    for i in range(n_trees):\n",
        "        if len(trees) == 0:\n",
        "\n",
        "            tree = reg_build_tree(X_train, y_train, min_leaf=5, max_depth=5, depth=0, max_leaves=1000)\n",
        "\n",
        "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
        "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
        "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
        "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
        "        else:\n",
        "            # Получим ответы на текущей композиции\n",
        "            z_train = gb_predict(X_train, trees, coefs, eta)\n",
        "            \n",
        "            # алгоритмы, начиная со второго, обучаем на сдвиг\n",
        "            tree = reg_build_tree(X_train, bias(y_train, z_train), min_leaf=5, max_depth=5, depth=0, max_leaves=1000)\n",
        "            \n",
        "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
        "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
        "\n",
        "        trees.append(tree)\n",
        "        \n",
        "    return trees, train_errors, test_errors"
      ],
      "metadata": {
        "id": "4KlqpzsN9EwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = reg_build_tree(X_train, y_train, min_leaf=5, max_depth=5, depth=0, max_leaves=1000)"
      ],
      "metadata": {
        "id": "gO3W8h7qSNFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_trees = 25\n",
        "max_depth = 5\n",
        "coefs = [1] * n_trees\n",
        "eta = 0.5\n",
        "counter_leaf = 0\n",
        "counter_node = 0\n",
        "trees, train_errors, test_errors = reg_gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
      ],
      "metadata": {
        "id": "w5WJoqyH92YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train, mse_test = evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
      ],
      "metadata": {
        "id": "GAUUKgYA-IP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train"
      ],
      "metadata": {
        "id": "z4FkUdnZ-RAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test"
      ],
      "metadata": {
        "id": "SMg6B0ur-TEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_boost (X_train, y_train):\n",
        "  count = 0 \n",
        "  X_train_boost = []\n",
        "  y_train_boost = []\n",
        "  while count < (X_train.shape[0]//2):\n",
        "      train_ind = np.random.randint(X_train.shape[0])\n",
        "      X_train_boost.append(X_train[train_ind])\n",
        "      y_train_boost.append(y_train[train_ind])\n",
        "  return X_train_boost, y_train_boost"
      ],
      "metadata": {
        "id": "rzB5KtUsFzmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_boost_gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
        "    \n",
        "    # eta - скорость обучения\n",
        "    # Деревья будем записывать в список\n",
        "    trees = []\n",
        "    \n",
        "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "    \n",
        "    for i in range(n_trees):\n",
        "        tree = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
        "\n",
        "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
        "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
        "        if len(trees) == 0:\n",
        "            # обучаем первое дерево на обучающей выборке\n",
        "            \n",
        "            X_train_boost, y_train_boost = grad_boost (X_train, y_train)\n",
        "            \n",
        "            tree.fit(X_train_boost, y_train_boost)\n",
        "            \n",
        "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
        "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
        "        else:\n",
        "            # Получим ответы на текущей композиции\n",
        "            X_train_boost, y_train_boost = grad_boost (X_train, y_train)\n",
        "            z_train = gb_predict(X_train_boost, trees, coefs, eta)\n",
        "            \n",
        "            # алгоритмы, начиная со второго, обучаем на сдвиг\n",
        "            X_train_boost, y_train_boost = grad_boost (X_train, y_train)\n",
        "            tree.fit(X_train_boost, bias(y_train_boost, z_train))\n",
        "            \n",
        "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
        "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
        "\n",
        "        trees.append(tree)\n",
        "        \n",
        "    return trees, train_errors, test_errors"
      ],
      "metadata": {
        "id": "CGb5U9Z1E9hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Число деревьев в ансамбле\n",
        "n_trees = 10\n",
        "\n",
        "# для простоты примем коэффициенты равными 1\n",
        "coefs = [1] * n_trees\n",
        "\n",
        "# Максимальная глубина деревьев\n",
        "max_depth = 3\n",
        "\n",
        "# Шаг\n",
        "eta = 0.05\n",
        "\n",
        "grad_boost_gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
      ],
      "metadata": {
        "id": "GZRmqmqfHL69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train, mse_test = evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
      ],
      "metadata": {
        "id": "lWvmry2ZJ9JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train"
      ],
      "metadata": {
        "id": "0tFifQn9KB1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test"
      ],
      "metadata": {
        "id": "VboJR2bUKDGF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Lesson_6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Содержание",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}